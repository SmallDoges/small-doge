<div align="center">
   <img src="./assets/org_icon.png" alt="smalldoges" width="100%">
</div>

<hr>

<div align="center">

![visitors](https://visitor-badge.laobi.icu/badge?page_id=SmallDoges/small-doge)
[![arXiv](https://img.shields.io/static/v1?label=arXiv&message=2412.11834&color=B31B1B&logo=arXiv)](https://arxiv.org/abs/2412.11834)
[![huggingface](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Models-FFD21E)](https://huggingface.co/collections/SmallDoge/doge-slm-679cc991f027c4a3abbded4a)
[![License: Apache-2.0](https://img.shields.io/badge/License-Apache--2.0-green.svg)](https://opensource.org/licenses/Apache-2.0)

*Small Doges æ­£åœ¨å»ºè®¾ä¸­, è®©æˆ‘ä»¬ä¸€èµ·å¼€å‘å§!ğŸ•ğŸ•ğŸ•*

[English](./README.md) | ç®€ä½“ä¸­æ–‡

</div>

# small-doge

* æœ¬é¡¹ç›®æ—¨åœ¨ä»**0**å¼€å§‹, æœ€å¿«ä»…ç”¨3å°æ—¶ï¼å³å¯è®­ç»ƒå‡ºä»…ä¸º13Må¤§å°çš„å¾®å‹è¯­è¨€æ¨¡å‹[Doge-20M](https://huggingface.co/SmallDoge/Doge-20M)!ğŸš€
* small dogeç³»åˆ—æå…¶è½»é‡, æœ€å°ç‰ˆæœ¬ä½“ç§¯çº¦æ˜¯ GPT3 çš„ **$\frac{1}{7800}$**, åŠ›æ±‚åšåˆ°æœ€æ™®é€šçš„ä¸ªäººGPUä¹Ÿå¯å¿«é€Ÿæ¨ç†ç”šè‡³è®­ç»ƒ.ğŸï¸
* æˆ‘ä»¬æä¾›äº†æ•°æ®é›†é¢„å¤„ç†ã€é¢„è®­ç»ƒã€ç›‘ç£å¾®è°ƒã€å¼ºåŒ–å­¦ä¹ åå¥½å¯¹é½çš„å…¨é˜¶æ®µä»£ç ã€è§†è§‰å¤šæ¨¡æ€VLM(æ­£åœ¨å¼€å‘)å’Œæ¨ç†å¾®è°ƒR1(æ­£åœ¨å¼€å‘).ğŸ§ª
* ç«™åœ¨å·¨äººçš„è‚©è†€ä¸Šå¯ä»¥çœ‹çš„æ›´è¿œ, å¸Œæœ›small dogeç³»åˆ—å°æ¨¡å‹èƒ½ä¸ºç ”ç©¶è€…æä¾›æ›´å¤šæ€è·¯, ä¸ºå®ç°**å…·èº«é€šç”¨äººå·¥æ™ºèƒ½**çš„é“è·¯æ·»ç –åŠ ç“¦.ğŸ¤–

> [!TIP]
> æˆ‘ä»¬å¸Œæœ›å°½å¯èƒ½ä½¿ç”¨å¼€æºå·¥å…·å’Œæ¡†æ¶æ¥ç®€åŒ–ä»æ•°æ®å¤„ç†åˆ°æ¨¡å‹è®­ç»ƒçš„è¿‡ç¨‹, ä»¥ä¾¿åˆå­¦è€…å¯ä»¥è½»æ¾ç†è§£å’Œä½¿ç”¨.ğŸ¤—

<img src="./assets/reasoning.gif" alt="streamlit"/>
<figcaption>Doge-60M-Instruct åœ¨ 11 ä»£ i7 CPU ç¬”è®°æœ¬ä¸Šå¿«é€Ÿæ¨ç†</figcaption>


## å…³äº

æœ¬é¡¹ç›®æ—¨åœ¨å¼€å‘ä¸€ç³»åˆ—åŠ¨æ€å¿«é€Ÿçš„å°å‹æ¨¡å‹, ä»¥ä¿ƒè¿›å…¶åœ¨å…·èº«æ™ºèƒ½é¢†åŸŸçš„åº”ç”¨, ç‰¹åˆ«æ˜¯åœ¨èµ„æºå—é™çš„ç¯å¢ƒä¸‹, æ»¡è¶³å®æ—¶å“åº”éœ€æ±‚, æ¨åŠ¨ä¸‹æ¸¸é¢†åŸŸçš„å®é™…åº”ç”¨è½åœ°.

> [!TIP]
> *æˆªè‡³2025-2-2*: small dogeç³»åˆ—å·²å®Œæˆäº†2ä¸ªå‹å·æ¨¡å‹çš„é¢„è®­ç»ƒ, æœ€å°ä»…éœ€20M, å³å¯å…·å¤‡æµç•…çš„å¯¹è¯èƒ½åŠ›!

| Model | tokens | max_train_steps | accumulate_steps | learning_rate | scheduler | warmup_ratio | decay_ratio | weight_decay | min_lr_rate |
|---|---|---|---|---|---|---|---|---|---|
| Doge-20M | 4B | 8,000 | 256 | 8e-3 | warmup_stable_decay | 0.1 | 0.1 | 0.01 | 0.0 |
| Doge-60M | 16B | 16,000 | 512 | 6e-3 | warmup_stable_decay | 0.1 | 0.1 | 0.01 | 0.0 |

> ä»¥ä¸‹ä¸¤ä¸ªå‹å·æ­£åœ¨é¢„è®­ç»ƒ, æ¬¢è¿æœ‰èƒ½åŠ›çš„ç ”ç©¶å‘˜å¸®å¿™(poor mançš„å“€åš)!ğŸ™

| Model | tokens | max_train_steps | accumulate_steps | learning_rate | scheduler | warmup_ratio | decay_ratio | weight_decay | min_lr_rate |
|---|---|---|---|---|---|---|---|---|---|
| Doge-160M | 32B | 24,000 | 768 | 4e-3 | warmup_stable_decay | 0.1 | 0.1 | 0.01 | 0.0 |
| Doge-320M | 64B | 32,000 | 1024 | 2e-3 | warmup_stable_decay | 0.1 | 0.1 | 0.01 | 0.0 |

<div align="center">
    <img src="./assets/doge_architecture.png" alt="drawing" width="600"/>
</div>

å¦‚å›¾æ‰€ç¤º, Doge æ¶æ„çš„åºåˆ—å˜æ¢éƒ¨åˆ†ä½¿ç”¨äº† `Dynamic Mask Attention`, å¯ä»¥ç†è§£ä¸ºåœ¨è®­ç»ƒæ—¶ä½¿ç”¨ä¸å€¼çŠ¶æ€ç›¸å…³çš„è‡ªæ³¨æ„åŠ›, åœ¨æ¨ç†æ—¶ä½¿ç”¨æ²¡æœ‰è¿‡å»çŠ¶æ€è¡°å‡çš„çŠ¶æ€ç©ºé—´, ä»¥è§£å†³ç°æœ‰çš„ Transformer æˆ– SSM åœ¨é•¿æ–‡æœ¬ä¸­è¿·å¤±çš„é—®é¢˜. Doge çš„çŠ¶æ€å˜æ¢éƒ¨åˆ†ä½¿ç”¨äº† `Cross Domain Mixture of Experts`, ç”±å¯†é›†çº¿æ€§å±‚å’Œç¨€ç–åµŒå…¥å±‚ç»„æˆ, å¹¶å¯ä»¥é¢å¤–å¢åŠ ç¨€ç–å‚æ•°, ä»¥ä»å¯†é›†æƒé‡æ£€æŸ¥ç‚¹ç»§ç»­è®­ç»ƒè€Œæ— éœ€é‡æ–°è®­ç»ƒæ•´ä¸ªæ¨¡å‹, ä»è€Œé™ä½æ¨¡å‹çš„æŒç»­è¿­ä»£æˆæœ¬. æ­¤å¤–, Doge è¿˜ä½¿ç”¨äº†å…·æœ‰å¯å­¦ä¹ å‚æ•°çš„ `RMSNorm` å’Œ `Residual` æ¥é€‚åº”æ·±åº¦æ¨¡å‹çš„æ¢¯åº¦èŒƒå›´.

**Dynamic Mask Attention æ¨¡å—**

![DMAttn](./assets/dmattn.png)
![DMAttn](./assets/mqar.png)

**Cross Domain Mixture of Experts æ¨¡å—**

![CDMoE](./assets/cdmoe.png)
![CDMoE](./assets/merm.png)


## å®‰è£…è¦æ±‚

æˆ‘ä»¬çš„ä»£ç åº“éœ€è¦ä»¥ä¸‹ç¯å¢ƒ:

- Windows æˆ– Linux
- NVIDIA GPU
- Python 3.10+
- PyTorch 2.0+
- CUDA 11.8+

ä½†æˆ‘ä»¬ä»ç„¶å¼ºçƒˆå»ºè®®æ‚¨å®‰è£…æœ€æ–°ç‰ˆæœ¬çš„ PyTorch å’Œ CUDA ä»¥è·å¾—æœ€ä½³æ€§èƒ½.

å½“ç„¶, æ‚¨ä¹Ÿå¯ä»¥ä½¿ç”¨å¼€æºçš„ [Docker PyTorch](https://catalog.ngc.nvidia.com/orgs/nvidia/containers/pytorch) é•œåƒæ¥é¿å…é…ç½®ç¯å¢ƒçš„éº»çƒ¦.

```bash
docker pull nvcr.io/nvidia/pytorch:24.12-py3
docker run --privileged --gpus all -it --name PyTorch --shm-size=32g -p 8888:8888 -p 6006:6006 --ulimit memlock=-1 --ulimit stack=67108864 -v <your code path>:/workspace -v <your datasets path>:/workspace/Doge/datasets nvcr.io/nvidia/pytorch:24.12-py3
```

- `pip install transformers`: æ‰€æœ‰åç»­å·¥ä½œçš„æ ¸å¿ƒæ¡†æ¶.
- `pip install datasets sentencepiece boto3`: ç”¨äºä¸‹è½½å’Œå¤„ç†æ•°æ®é›†.
- `pip install accelerate`: ç”¨äºåˆ†å¸ƒå¼è®­ç»ƒ.
- `pip install trl`: ç”¨äºå¼ºåŒ–å­¦ä¹ å¾®è°ƒ.


## å®‰è£…

```bash
git clone https://github.com/SmallDoges/small-doge.git
cd small-doge
pip install -e .
```


## å¿«é€Ÿå…¥é—¨

æˆ‘ä»¬å·²ç»ç¼–å†™äº†ä¸€ä¸ª [notebook](./examples/notebook.ipynb) å’Œ [è®­ç»ƒæŒ‡å—](./recipes/doge/README.md) æ¥æ¼”ç¤ºæ•°æ®é›†å¤„ç†ã€æ¨¡å‹è®­ç»ƒå’Œæ¨¡å‹è¯„ä¼°çš„æ•´ä¸ªè¿‡ç¨‹. æ‚¨è¿˜å¯ä»¥ç‹¬ç«‹ä½¿ç”¨å·²ç»å‘å¸ƒçš„æ¨¡å‹, å¦‚æœæ„Ÿå…´è¶£è¯·è¯¦ç»†é˜…è¯»notebookæˆ–è®­ç»ƒæŒ‡å—, é‡Œé¢æœ‰å…·ä½“çš„æ­¥éª¤å’Œç»†èŠ‚ï¼


## å‹å·å‘å¸ƒ

### Doge-CheckPoint

![wsd_scheduler](./assets/wsd_scheduler.png)

Doge ä½¿ç”¨ `wsd_scheduler` ä½œä¸ºè®­ç»ƒè°ƒåº¦å™¨, å°†å­¦ä¹ ç‡åˆ†ä¸º `warmup`, `stable` å’Œ `decay` ä¸‰ä¸ªé˜¶æ®µ. å®ƒå…è®¸æˆ‘ä»¬åœ¨ `stable stage` ä¸­çš„ä»»ä½•æ–°æ•°æ®é›†ä¸Šä»ä»»ä½•æ£€æŸ¥ç‚¹ç»§ç»­è®­ç»ƒ, è€Œæ²¡æœ‰è®­ç»ƒçš„æŸå¤±æ³¢åŠ¨.

ä»¥ä¸‹æ˜¯åœ¨æ¯ä¸ªæ£€æŸ¥ç‚¹ç»§ç»­è®­ç»ƒæ‰€éœ€çš„åˆå§‹å­¦ä¹ ç‡:

- **[Doge-20M](https://huggingface.co/SmallDoge/Doge-20M-checkpoint)**: 8e-3
- **[Doge-60M](https://huggingface.co/SmallDoge/Doge-60M-checkpoint)**: 6e-3
- **[Doge-160M](https://huggingface.co/SmallDoge/Doge-160M-checkpoint)**: 4e-3
- **Doge-320M**: 2e-3

| æ¨¡å‹ | å­¦ä¹ ç‡ | è°ƒåº¦å™¨ | é¢„çƒ­æ­¥æ•° | ç¨³å®šæ­¥æ•° |
|-------|---------------|----------|--------------|--------------|
| [Doge-20M]((https://huggingface.co/SmallDoge/Doge-20M-checkpoint)) | 8e-3 | wsd_scheduler | 800 | 6400 |
| [Doge-60M](https://huggingface.co/SmallDoge/Doge-60M-checkpoint) | 6e-3 | wsd_scheduler | 1600 | 12800 |
| [Doge-160M](https://huggingface.co/SmallDoge/Doge-160M-checkpoint) | 4e-3 | wsd_scheduler | 2400 | 19200 |
| Doge-320M | 2e-3 | wsd_scheduler | 3200 | 25600 |

### Doge-SLM

**é¢„è®­ç»ƒ**:
| æ¨¡å‹ | è®­ç»ƒæ•°æ® | æ­¥æ•° | ä¸Šä¸‹æ–‡é•¿åº¦ | ä»¤ç‰Œ | å­¦ä¹ ç‡ | æ‰¹é‡å¤§å° | ç²¾åº¦ |
|---|---|---|---|---|---|---|---|
| [Doge-20M](https://huggingface.co/SmallDoge/Doge-20M) | [HuggingFaceTB/smollm-corpus](https://huggingface.co/datasets/HuggingFaceTB/smollm-corpus) | 8k  | 2048 | 4B | 8e-3 | 0.5M | bfloat16 |
| [Doge-60M](https://huggingface.co/SmallDoge/Doge-60M) | [HuggingFaceTB/smollm-corpus](https://huggingface.co/datasets/HuggingFaceTB/smollm-corpus) | 16k  | 2048 | 16B | 6e-3 | 1M | bfloat16 |

**è¯„ä¼°**:
| æ¨¡å‹ | MMLU | TriviaQA | ARC-E | ARC-C | PIQA | HellaSwag | OBQA | Winogrande | CPU ä¸Šçš„ tokens / s |
|---|---|---|---|---|---|---|---|---|---|
| [Doge-20M](https://huggingface.co/SmallDoge/Doge-20M) | 25.43 | 0.03 | 36.83 | 22.78 | 58.38 | 27.25 | 25.60 | 50.20 | 142 |
| [Doge-60M](https://huggingface.co/SmallDoge/Doge-60M) | 26.41 | 0.18 | 50.46 | 25.34 | 61.43 | 31.45 | 28.00 | 50.75 | 62 |

> æ‰€æœ‰è¯„ä¼°éƒ½æ˜¯åœ¨five-shotè®¾ç½®ä¸‹å®Œæˆçš„, åœ¨åŸºå‡†æµ‹è¯•ä¸­æ²¡æœ‰é¢å¤–çš„è®­ç»ƒ.

**ç›‘ç£å¾®è°ƒ**:
| æ¨¡å‹ | è®­ç»ƒæ•°æ® | è½®æ¬¡ | ä¸Šä¸‹æ–‡é•¿åº¦ | å­¦ä¹ ç‡ | æ‰¹é‡å¤§å° | ç²¾åº¦ |
|---|---|---|---|---|---|---|
| [Doge-20M-Instruct-SFT](https://huggingface.co/SmallDoge/Doge-20M-Instruct-SFT) | [HuggingFaceTB/smoltalk](https://huggingface.co/datasets/HuggingFaceTB/smoltalk) | 2 | 2048 | 8e-4 | 0.25M | bfloat16 |
| [Doge-60M-Instruct-SFT](https://huggingface.co/SmallDoge/Doge-60M-Instruct-SFT) | [HuggingFaceTB/smoltalk](https://huggingface.co/datasets/HuggingFaceTB/smoltalk) | 2 | 2048 | 6e-4 | 0.25M | bfloat16 |

**è¿‘ç«¯ä¼˜åŒ–å¾®è°ƒ**:
| æ¨¡å‹ | è®­ç»ƒæ•°æ® | è½®æ¬¡ | ä¸Šä¸‹æ–‡é•¿åº¦ | å­¦ä¹ ç‡ | æ‰¹é‡å¤§å° | ç²¾åº¦ |
|---|---|---|---|---|---|---|
| [Doge-20M-Instruct](https://huggingface.co/SmallDoge/Doge-20M-Instruct) | [HuggingFaceH4/ultrafeedback_binarized](https://huggingface.co/datasets/HuggingFaceH4/ultrafeedback_binarized) | 2 | 1024 | 8e-5 | 0.125M | bfloat16 |
| [Doge-60M-Instruct](https://huggingface.co/SmallDoge/Doge-60M-Instruct) | [HuggingFaceH4/ultrafeedback_binarized](https://huggingface.co/datasets/HuggingFaceH4/ultrafeedback_binarized) | 2 | 1024 | 6e-5 | 0.125M | bfloat16 |

**ç¯å¢ƒ**:

- é•œåƒ: nvcr.io/nvidia/pytorch:24.12-py3
- ç¡¬ä»¶: 1x NVIDIA RTX 4090
- è½¯ä»¶: Transformers, TRL


## å¼•ç”¨

å¦‚æœæ‚¨ä½¿ç”¨æ­¤ä»£ç åº“, æˆ–è€…è®¤ä¸ºæˆ‘ä»¬çš„å·¥ä½œæœ‰ä»·å€¼, è¯·å¼•ç”¨æˆ‘ä»¬çš„è®ºæ–‡:

```bibtex
@misc{shi2024wonderfulmatrices,
      title={Wonderful Matrices: Combining for a More Efficient and Effective Foundation Model Architecture}, 
      author={Jingze Shi and Bingheng Wu},
      year={2024},
      eprint={2412.11834},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2412.11834}, 
}
```